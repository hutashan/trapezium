#log level for your application
logLevel = "DEBUG"

#appName will be used as Spark Application name.
#You can use this name to find your application on Yarn
appName = "commons-datasimulation"

#appSchema will be used to access schema.
#Provide the schema your workflows will connect to persist, e.g., hive schema
persistSchema = "app_mgr"

#Application Manager will serialize objects to make sure that components are serializable
#Make sure you provide a directory which user has write access to
tempDir = "/tmp/"

sparkConf = {
  #Kryo Serializer
  #If you use Kryo serialization, set this class to register your custom classes with Kryo.
  #This property is useful if you need to register your classes in a custom way, e.g. to specify a custom field serializer.
  #Otherwise spark.kryo.classesToRegister is simpler
  ##kryoSerializer = ""

  #If you use Kryo serialization, give a comma-separated list of custom class names to register with Kryo
  kryoRegistratorClass = "com.verizon.bda.trapezium.framework.utils.EmptyRegistrator"
  #Akka Frame Size
  #Maximum message size to allow in "control plane" communication (for serialized tasks and task results), in MB.
  #Increase this if your tasks need to send back large results to the driver (e.g. using collect() on a large dataset).
  #spark.akka.frameSize = 100
  #memsql.host = "146.1.180.10"
  #memsql.user = "root"
  #memsql.password = "read0nly"
}

#ZooKeeper connection
zookeeperList = "bda-azk-1.verizon.com:2181,bda-azk-2.verizon.com:2181,bda-azk-3.verizon.com:2181"
#zookeeperList = "localhost:2181"

#Kafka Brokers
kafkabrokers = "bda-abk.verizon.com:9092,bda-abk-1.verizon.com:9092"

#ApplicationStartupClass - Has to be implemented by the Vertical
applicationStartupClass = "com.verizon.bda.appstartup.AppStartup"
fileSystemPrefix="hdfs://Saiphdevqa"
