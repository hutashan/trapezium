runMode = "BATCH"
dataSource = "HDFS"
singleRun=true
hdfsFileBatch = {
  batchTime = 10
  timerStartDelay = 1
  batchInfo = [
    {
      name = "datasimulation"
      dataDirectory = {
       saiph-devqa= "/tmp/dataslice/*/*parquet*"
        local=  "tmp/dataslice"
      }
        readFullDataset = "true"
        fileFormat=parquet
        groupFile = {
          dateformat = "yyyy-MM-dd HH-mm"
          startDateIndex = 15
          endDateIndex = 31
        }
        validation = {
          columns = ["col1","col2","col3","col4","col5","col6","col7","col8","col9","col10","col11","col12","col13","col14","col15","col16","col17"]
          datatypes = ["String","String","String","String","String","String","String","String","String","String","String","String","String","String","String","String","String"]
          dateFormat = "yyyy-MM-dd HH:mm:ss"
          delimiter = ","
          minimumColumn = 17
          rules = {

          }
        }
      }
  ]
}
dataSimulationInfo={
  simulationMode="hdfs"
  outputpath="tmp/datasimulation"
  interval=5
 }
transactions = [{
  transactionName = "com.verizon.bda.datasimulation.DataSimulation"
  inputData = [{
    name = "datasimulation"
  }]
  persistDataName = "testOutput"
}]
