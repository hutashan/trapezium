runMode = "BATCH"
dataSource = "HDFS"
singleRun=true
#HDFS File Batch configs
#For Batch transactions, details about the data is present here
#batchInfo - List of data sources for which RDD's will be created by the Application Manager
#batchInfo.name - Name of the batch datasource
#batchInfo.dataDirectory - HDFS directory where the datasource resides
#HDFS File Batch configs
#For Batch transactions, details about the data is present here
#batchInfo - List of data sources for which RDD's will be created by the Application Manager
#batchInfo.name - Name of the batch datasource
#batchInfo.dataDirectory - HDFS directory where the datasource resides
hdfsFileBatch = {
  batchTime = 10
  timerStartDelay = 1
  batchInfo = [
    {
      name = "datasliceworkflow"
      dataDirectory = {
        local = "src/test/data/testdata"
        saiph-devqa = "/netintel/netflow/20151020_1445383324726_ae8d2b1b40c9a8cb"
      }
      readFullDataset = "true"
      validation = {
        columns = ["col1", "col2", "col3", "col4", "col5", "col6", "col7", "col8", "col9", "col10", "col11", "col12", "col13", "col14", "col15", "col16", "col17"]
        datatypes = ["String", "String", "String", "String", "String", "String", "String", "String", "String", "String", "String", "String", "String", "String", "String", "String", "String"]
        dateFormat = "yyyy-MM-dd HH:mm:ss"
        delimiter = ","
        minimumColumn = 17
        rules = {

        }
      }
    }
  ]
}

dataSliceInfo = {
  slicemode = ["slice","growth"]
  #slicemode = ["slice"]
  slicecol = "col1"
  growthcol = ["col14", "col12"]
  growthColTypes = ["com.verizon.bda.growth.SampleIntGrowth",
    "com.verizon.bda.growth.SampleStringGrowth"]
  outputpath = "tmp/dataslice"
  repetition = 5
}

transactions = [{
  transactionName = "com.verizon.bda.dataslice.DataSlicer"
  inputData = [{
    name = "datasliceworkflow"
  }]
  persistDataName = "testOutput"
}]
